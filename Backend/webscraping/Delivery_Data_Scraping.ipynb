{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping data from the web in order to work out if restaurants deliver or not during COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ec4008006c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure webdriver to use Chrome browser, we have to set the path to chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Safari(executable_path='/usr/bin/safaridriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome(\"/usr/lib/chromium-browser/chromedriver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer the below code to open the URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.get(\"https://www.therailwayinnbotley.com/delivery\")\n",
    "driver.get(\"https://www.squaremeal.co.uk/restaurants/so31-1et-southampton/local-restaurants\")\n",
    "# driver.get(\"https://www.squaremeal.co.uk/restaurants/so31-1et-southampton/local-restaurants?page=31\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have written the code to open the URL, itâ€™s time to extract the data from the website. As mentioned earlier, the data we want to extract is nested in `<div>` tags. So, I will find the div tags with those respective class-names, extract the data and store the data in a variable. Refer the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = driver.page_source\n",
    "soup = BeautifulSoup(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = soup.find('body')\n",
    "the_contents_of_body_without_body_tags = body.findChildren(recursive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = str(the_contents_of_body_without_body_tags[0]).replace(\"+\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_selection = soup.findAll(\"a\", {\"class\": \"js-track-listing-click\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_ends_of_links=list()\n",
    "# for i in range(len(test_selection)):\n",
    "#     list_of_ends_of_links.append(str(test_selection[i]).split(\"restaurants/\")[1].split('\">')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in list(dict.fromkeys(list_of_ends_of_links)):\n",
    "#     print(\"https://www.squaremeal.co.uk/restaurants/\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.prettify()\n",
    "# test_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_instances = list()\n",
    "for index in [m.start() for m in re.finditer('delivery', test_string)]:\n",
    "    print(test_string[index-30:].split(\"<\")[0])\n",
    "    list_of_instances.append(test_string[index-30:].split(\"<\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'Product Name':products,'Price':prices,'Rating':ratings}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_ends_of_links=list()\n",
    "for i in range(1, 31):\n",
    "    initial_site = \"https://www.squaremeal.co.uk/restaurants/so31-1et-southampton/local-restaurants?page=\"+str(i)\n",
    "    driver.get(initial_site)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    test_selection = soup.findAll(\"a\", {\"class\": \"js-track-listing-click\"})\n",
    "\n",
    "    for i in range(len(test_selection)):\n",
    "        list_of_ends_of_links.append(str(test_selection[i]).split(\"restaurants/\")[1].split('\">')[0])\n",
    "\n",
    "        ##TODO: instead of printing dive further in and find the website of each restaurant, then search for delivery in said restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_ends_of_links = list(dict.fromkeys(list_of_ends_of_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_links_to_actual_websites = list()\n",
    "for i in range(len(list_of_ends_of_links)):\n",
    "    code = list_of_ends_of_links[i].split(\"_\")[1]\n",
    "    website_link = \"https://www.squaremeal.co.uk/restaurants/website?id=\"+code\n",
    "    list_of_links_to_actual_websites.append(website_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for website in list_of_links_to_actual_websites:\n",
    "    driver.get(website)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "\n",
    "    body = soup.find('body')\n",
    "    the_contents_of_body_without_body_tags = body.findChildren(recursive=False)\n",
    "\n",
    "    test_string = str(the_contents_of_body_without_body_tags[0]).replace(\"+\", \" \")\n",
    "    \n",
    "    list_of_instances = list()\n",
    "    for index in [m.start() for m in re.finditer('closed', test_string)]:\n",
    "#         instance_that_matches = test_string[index-30:].split(\"<\")[0]\n",
    "        instance_that_matches = test_string[index-30:index+30]\n",
    "        print(instance_that_matches)\n",
    "        list_of_instances.append(instance_that_matches)\n",
    "    print(list_of_instances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
